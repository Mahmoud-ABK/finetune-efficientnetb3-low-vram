





# Core Python and system utilities
import os
import time

# Numerical and data handling
import numpy as np

# PyTorch and related libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
import torchvision.models as models
import torchvision.transforms as transforms

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Metrics and evaluation
from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support

# Progress tracking
from tqdm import tqdm


# reproducibility
torch.manual_seed(42)
np.random.seed(42)






# CUDA check and setup
print(f"CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    device = torch.device("cuda")
    torch.cuda.manual_seed_all(42)
    torch.cuda.empty_cache()  # Clear any residual memory
    torch.backends.cudnn.benchmark = False  # Disable for deterministic results
    torch.backends.cudnn.enabled = True
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Initial VRAM Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB")
    print(f"Initial VRAM Reserved: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB")
else:
    device = torch.device("cpu")
    print("Using CPU. Performance may be slow.")

# Define dataset paths
dataset_root = "./dataset"
train_path = os.path.join(dataset_root, "train")
val_path = os.path.join(dataset_root, "val")
test_path = os.path.join(dataset_root, "test")





# Load datasets using ImageFolder 
train_dataset = datasets.ImageFolder(train_path)
val_dataset = datasets.ImageFolder(val_path)
test_dataset = datasets.ImageFolder(test_path)

# Create DataLoaders
batch_size = 64
num_workers = 2  # number of subprocesses
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=num_workers,
    pin_memory=True
)
val_loader = DataLoader(
    val_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True
)
test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True
)

# Verify dataset sizes and classes
try:
    assert len(train_dataset.classes) == 2, "Expected 2 classes: guide_dogs, non_guide_dogs"
    print(f"Train samples: {len(train_dataset)}")
    print(f"Validation samples: {len(val_dataset)}")
    print(f"Test samples: {len(test_dataset)}")
    print(f"Classes: {train_dataset.classes}")
except AssertionError as e:
    print(f"Dataset Error: {e}")
    raise
except Exception as e:
    print(f"Error loading dataset: {e}")
    raise








model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)
model.eval()
model = model.to(device)

# Get the transforms from the model weights 
transform = models.EfficientNet_B3_Weights.IMAGENET1K_V1.transforms()
# Apply transforms to datasets
train_dataset.transform = transform
val_dataset.transform = transform
test_dataset.transform = transform


# Guide dog breeds in ImageNet class label format
guide_dog_indexes = [235, 207, 208, 232, 245, 236, 248, 247, 279]



# Evaluation function
def evaluate_split(split_path, dataset, model, device):
    loader = DataLoader(dataset, batch_size=32, shuffle=False)
    guide_dog_class_index = dataset.class_to_idx["guide_dogs"]
    correct = 0
    total = 0
    for images, labels in tqdm(loader, desc=f"Evaluating {os.path.basename(split_path)}"):
        images = images.to(device)
        with torch.no_grad():
            outputs = model(images)
            preds = torch.argmax(outputs, dim=1)
            for i in range(len(preds)):
                predicted_idx = preds[i].item()
                is_pred_guide = predicted_idx in guide_dog_indexes
                is_true_guide = labels[i].item() == guide_dog_class_index
                if is_pred_guide == is_true_guide:
                    correct += 1
                total += 1
    accuracy = 100 * correct / total
    print(f"âœ… Accuracy on {os.path.basename(split_path)}: {accuracy:.2f}%")
    return accuracy

# Evaluate on all splits
results = {}
for split, dataset in [("train", train_dataset), ("val", val_dataset), ("test", test_dataset)]:
    acc = evaluate_split(os.path.join(dataset_root, split), dataset, model, device)
    results[split] = acc

print("\nðŸ“Š Summary:")
for split, acc in results.items():
    print(f"{split}: {acc:.2f}%")











transform = models.EfficientNet_B3_Weights.IMAGENET1K_V1.transforms() 
print (transform)





# Define custom training transforms
train_transform = transforms.Compose([
    transforms.Resize((300, 300)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.RandomResizedCrop(300, scale=(0.8, 1.0)),
    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET), #Applies learned augmentation policies for robustness.
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])





# Verify shapes
train_dataset.transform = train_transform
data_iter = iter(train_loader)
images, labels = next(data_iter)
print(f"Image batch shape: {images.shape}")  # Expected: [batch_size, 3, 300, 300]
print(f"Label batch shape: {labels.shape}")  # Expected: [batch_size]
print(f"Labels: {labels}")
print(f"Sample tensor dimensions: {images[0].shape}")





# Freeze all layers except classifier
for param in model.features.parameters():
    param.requires_grad = False








print(model.classifier)





#Replace classifier for binary classification
model.classifier = nn.Sequential(
    nn.Linear(1536, 256),
    nn.BatchNorm1d(256),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(256, 1)
)
model = model.to(device)  # Ensure model is on GPU
print(model.classifier)





for idx, param in enumerate(model.parameters()):
    print(f"({idx}, {param.requires_grad})", end=' ')


get_ipython().getoutput("nvidia-smi")





## BCE
# Loss and optimizer
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.classifier.parameters(), lr=0.01)

# Training function
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):
    history = {"train_loss": [], "train_acc": [], "val_loss": [], "val_acc": []}
    
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        train_preds, train_targets = [], []
        
        for data, target in train_loader:
            data, target = data.to(device), target.float().to(device).view(-1, 1)  # Float targets, shape (batch_size, 1)
            optimizer.zero_grad()
            output = model(data)  # Output: (batch_size, 1) logits
            loss = criterion(output, target)  # BCEWithLogitsLoss
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * data.size(0)

            # Apply sigmoid for predictions
            probs = torch.sigmoid(output)
            preds = (probs > 0.5).float()  # Threshold at 0.5
            train_preds.extend(preds.cpu().numpy().flatten())
            train_targets.extend(target.cpu().numpy().flatten())

        # Validation
        model.eval()
        val_loss = 0.0
        val_preds, val_targets = [], []
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.float().to(device).view(-1, 1)
                output = model(data)  # (batch_size, 1) logits
                loss = criterion(output, target)
                val_loss += loss.item() * data.size(0)

                probs = torch.sigmoid(output)
                preds = (probs > 0.5).float()
                val_preds.extend(preds.cpu().numpy().flatten())
                val_targets.extend(target.cpu().numpy().flatten())

        # Metrics
        train_loss /= len(train_loader.dataset)
        val_loss /= len(val_loader.dataset)
        train_acc = accuracy_score(train_targets, train_preds)
        val_acc = accuracy_score(val_targets, val_preds)

        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["train_acc"].append(train_acc)
        history["val_acc"].append(val_acc)

        print(f"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
        
   # Clear memory after epoch
    
    return history


# Train the model
history = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)





# Evaluation function
def evaluate_model(model, loader):
    model.eval()
    preds, targets = [], []
    with torch.no_grad():
        for data, target in loader:
            data, target = data.to(device), target.float().to(device).view(-1, 1)
            output = torch.sigmoid(model(data))
            preds.extend((output > 0.5).float().cpu().numpy().flatten())
            targets.extend(target.cpu().numpy().flatten())
    
    acc = accuracy_score(targets, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(targets, preds, average="binary")
    return acc, precision, recall, f1, preds, targets

# Evaluate
test_acc, test_precision, test_recall, test_f1, test_preds, test_targets = evaluate_model(model, test_loader)
print(f"Test Accuracy: {test_acc:.4f}")
print(f"Test Precision: {test_precision:.4f}")
print(f"Test Recall: {test_recall:.4f}")
print(f"Test F1-Score: {test_f1:.4f}")


# Plot loss and accuracy
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history["train_loss"], label="Train Loss")
plt.plot(history["val_loss"], label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history["train_acc"], label="Training Accuracy")
plt.plot(history["val_acc"], label="Validation Accuracy")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

plt.tight_layout()
plt.show()


# Confusion matrix
cm = confusion_matrix(test_targets, test_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non-Guide", "Guide"], yticklabels=["Non-Guide", "Guide"])
plt.title("Confusion Matrix (Test Set)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()





get_ipython().getoutput("nvidia-smi")





# Save model
torch.save(model.state_dict(), "./model/frozen_model.pth")
print("Model saved as 'frozen_model.pth'")





from IPython import get_ipython
import torch

# Clear GPU memory
if torch.cuda.is_available():
    torch.cuda.empty_cache()
print("GPU memory cleared.")

# Shut down the kernel
get_ipython().kernel.do_shutdown(restart=True)



